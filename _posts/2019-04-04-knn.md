---
layout: post
comments: true
title: '[알고리즘] KNN'
categories: [bigdata]
tags: [ml]
date: 2019-04-04
---

# K-최근접 이웃법 (Nearest Neighbor) - KNN

최근접 이웃법은 새로운 데이터를 입력받았을 때 가장 가까이 있는 것이 무엇이냐를 중심으로 새로운 데이터의 종류를 정해주는 알고리즘이다.

![knn](/assets/img/post/knn/knn-1.png){: width="400px" }

그림에서 보는것 처럼 기존 데이터가 파랑색과 주황색으로 데이터가 분류되었다고 한다면 물음표 데이터가 들어왔을때 이 데이터는 어떤 색상으로 분류가 되어야 할까요? 

최근접 이웃법 말그대로 가까운 것에 따른 분류이기 때문에 주황색으로 분류할 것 입니다. 정말 간단하고 직관적인 알고리즘 입니다.

하지만 단순히 가장 가까이에 있는 것으로 분류를 하는것이 문제가 되는 경우도 있습니다.

다음의 경우를 살펴 보면

![knn](/assets/img/post/knn/knn-2.png){: width="400px" }

이번에는 문제가 약간 복잡해 집니다. 이론데로 가장 가까운것은 파랑색이기때문에 파랑색으로 분류를 해야 할것 같지만, 주변을 보면 대부분 주황색이 보입니다. 왠지 파랑색으로 분류하면 안될 것 같다는 생각이 든다....

따라서 단순히 가까운것에 따른 분류에서 주변에 있는 몇개의 것들중에 많은 것으로 분류하게 되면 이 문제는 어느정도 해결이 된다.

물음표 주변(큰원)에는 4개의 데이터가 있는데 그중 세개가 주황색, 한개가 파랑색 이다. 따라서 물음표는 주황색으로 분류를 하는 것이다.

그렇다면 주변의 범위 즉 주변 데이터의 갯수에 대한 기준이 있어야 할 것 같은데 위에서는 4개로 정하였다. 즉 K=4가 되는 최근접 이웃법이라고 설명할 있는데, 그래서 KNN 알고리즘 이라고 하는 것이다.

![knn](/assets/img/post/knn/knn-3.png){: width="400px" }

만약 K=1로 한다면 처음 정의하였던 것처럼 물음표는 가장 가까운 한개의 요소만 바라보게 될 테니 파랑색으로 분류를 하게 될 것이다. 즉, K의 값에 따라 물음표가 어느 범주로 분류 될 것인지가 결정 된다.

그럼 과연 K는 몇이어야 좋은 것일까? 최선의 K값을 선택하는것은 데이터마다 다르게 접근해야 한다. 